{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ed8937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset from politicians- US Senate election 2021\n",
    "import pandas as pd\n",
    "\n",
    "splits = {'train': 'data/train-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet'}\n",
    "df = pd.read_parquet(\"hf://datasets/m-newhauser/senator-tweets/\" + splits[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4f77494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "      <th>party</th>\n",
       "      <th>labels</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-13 19:47:44</td>\n",
       "      <td>1448374915636383745</td>\n",
       "      <td>SenatorHassan</td>\n",
       "      <td>Happy th birthday to the @USNavy! The strength...</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.026915843, 0.087234065, 0.018707331, -0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-06-30 14:53:13</td>\n",
       "      <td>1410250073003462656</td>\n",
       "      <td>SenatorMenendez</td>\n",
       "      <td>The greatest generation's investment in infras...</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.024044158, -0.0048382296, 0.09699756, -0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-08-08 01:11:29</td>\n",
       "      <td>1424176405881966599</td>\n",
       "      <td>SenBillCassidy</td>\n",
       "      <td>Thanks to @SenTedCruz and  @SenatorWarnock, th...</td>\n",
       "      <td>Republican</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.002620128, -0.042515174, 0.065084696, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-04-14 14:02:49</td>\n",
       "      <td>1382333523567185921</td>\n",
       "      <td>SenBlumenthal</td>\n",
       "      <td>/ To get lasting change we cant just lock up t...</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.045103785, 0.0762336, -0.011798679, -0.044...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-11 16:06:38</td>\n",
       "      <td>1469700160934621188</td>\n",
       "      <td>SenatorBraun</td>\n",
       "      <td>Today were celebrating years of the Hoosier st...</td>\n",
       "      <td>Republican</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.038810886, 0.11611319, 0.06621017, -0.0184...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79749</th>\n",
       "      <td>2021-04-05 22:58:21</td>\n",
       "      <td>1379206803653857286</td>\n",
       "      <td>SenAlexPadilla</td>\n",
       "      <td>You spelled \"voter suppression\" wrong. https:/...</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.029901493, 0.051829427, 0.046873894, 0.0266...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79750</th>\n",
       "      <td>2021-06-08 17:27:28</td>\n",
       "      <td>1402316360542208003</td>\n",
       "      <td>RogerMarshallMD</td>\n",
       "      <td>.@VP: This is no laughing matter. Your policie...</td>\n",
       "      <td>Republican</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.053853884, 0.03127704, -0.0046211034, 0.018...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79751</th>\n",
       "      <td>2021-08-30 13:35:24</td>\n",
       "      <td>1432336152225275907</td>\n",
       "      <td>SenatorTimScott</td>\n",
       "      <td>In the wake of last weeks attack, we are etern...</td>\n",
       "      <td>Republican</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.040830877, 0.11338369, 0.040611953, -0.000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79752</th>\n",
       "      <td>2021-03-27 13:41:58</td>\n",
       "      <td>1375805294454976514</td>\n",
       "      <td>SenWhitehouse</td>\n",
       "      <td>This is the right thing to do. There needs to ...</td>\n",
       "      <td>Democrat</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.01618602, 0.048982657, -0.07600288, -0.002...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79753</th>\n",
       "      <td>2021-12-16 18:43:53</td>\n",
       "      <td>1471551670765199360</td>\n",
       "      <td>SenatorHagerty</td>\n",
       "      <td>Building on the Trump Admins Jan '21 determina...</td>\n",
       "      <td>Republican</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.07644176, 0.0325673, 0.013120744, -0.00845...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79754 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date                   id         username  \\\n",
       "0      2021-10-13 19:47:44  1448374915636383745    SenatorHassan   \n",
       "1      2021-06-30 14:53:13  1410250073003462656  SenatorMenendez   \n",
       "2      2021-08-08 01:11:29  1424176405881966599   SenBillCassidy   \n",
       "3      2021-04-14 14:02:49  1382333523567185921    SenBlumenthal   \n",
       "4      2021-12-11 16:06:38  1469700160934621188     SenatorBraun   \n",
       "...                    ...                  ...              ...   \n",
       "79749  2021-04-05 22:58:21  1379206803653857286   SenAlexPadilla   \n",
       "79750  2021-06-08 17:27:28  1402316360542208003  RogerMarshallMD   \n",
       "79751  2021-08-30 13:35:24  1432336152225275907  SenatorTimScott   \n",
       "79752  2021-03-27 13:41:58  1375805294454976514    SenWhitehouse   \n",
       "79753  2021-12-16 18:43:53  1471551670765199360   SenatorHagerty   \n",
       "\n",
       "                                                    text       party  labels  \\\n",
       "0      Happy th birthday to the @USNavy! The strength...    Democrat       1   \n",
       "1      The greatest generation's investment in infras...    Democrat       1   \n",
       "2      Thanks to @SenTedCruz and  @SenatorWarnock, th...  Republican       0   \n",
       "3      / To get lasting change we cant just lock up t...    Democrat       1   \n",
       "4      Today were celebrating years of the Hoosier st...  Republican       0   \n",
       "...                                                  ...         ...     ...   \n",
       "79749  You spelled \"voter suppression\" wrong. https:/...    Democrat       1   \n",
       "79750  .@VP: This is no laughing matter. Your policie...  Republican       0   \n",
       "79751  In the wake of last weeks attack, we are etern...  Republican       0   \n",
       "79752  This is the right thing to do. There needs to ...    Democrat       1   \n",
       "79753  Building on the Trump Admins Jan '21 determina...  Republican       0   \n",
       "\n",
       "                                              embeddings  \n",
       "0      [-0.026915843, 0.087234065, 0.018707331, -0.03...  \n",
       "1      [0.024044158, -0.0048382296, 0.09699756, -0.03...  \n",
       "2      [-0.002620128, -0.042515174, 0.065084696, 0.01...  \n",
       "3      [-0.045103785, 0.0762336, -0.011798679, -0.044...  \n",
       "4      [-0.038810886, 0.11611319, 0.06621017, -0.0184...  \n",
       "...                                                  ...  \n",
       "79749  [0.029901493, 0.051829427, 0.046873894, 0.0266...  \n",
       "79750  [0.053853884, 0.03127704, -0.0046211034, 0.018...  \n",
       "79751  [-0.040830877, 0.11338369, 0.040611953, -0.000...  \n",
       "79752  [-0.01618602, 0.048982657, -0.07600288, -0.002...  \n",
       "79753  [-0.07644176, 0.0325673, 0.013120744, -0.00845...  \n",
       "\n",
       "[79754 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#analizar la posicion politica de una persona usando embeddings \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49de1866",
   "metadata": {},
   "source": [
    "#### presidentia elections 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b588c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "jb = pd.read_csv(\"preliminares/jb_part.csv\")\n",
    "jb[\"C\"] = 1\n",
    "dt = pd.read_csv(\"preliminares/dt_part.csv\")\n",
    "jb[\"C\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "292ea90b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>source</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>...</th>\n",
       "      <th>user_location</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>continent</th>\n",
       "      <th>state</th>\n",
       "      <th>state_code</th>\n",
       "      <th>collected_at</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>445280</td>\n",
       "      <td>2020-11-04 22:12:10</td>\n",
       "      <td>1.324112e+18</td>\n",
       "      <td>Va #Biden adelante... https://t.co/RLELfTU8NW</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>8.758018e+07</td>\n",
       "      <td>Abdiel Augusto</td>\n",
       "      <td>augustoexp</td>\n",
       "      <td>...</td>\n",
       "      <td>Arraiján / Panamá</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-11-05 12:49:02.541625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38488</td>\n",
       "      <td>2020-10-17 13:32:59</td>\n",
       "      <td>1.317459e+18</td>\n",
       "      <td>Did the #democrats not try to impeach #Trump o...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>4.779699e+07</td>\n",
       "      <td>Tom Dooley</td>\n",
       "      <td>tomofsnj</td>\n",
       "      <td>...</td>\n",
       "      <td>USA</td>\n",
       "      <td>39.783730</td>\n",
       "      <td>-100.445882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-10-21 05:39:00.255677220</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>607448</td>\n",
       "      <td>2020-11-07 17:06:21</td>\n",
       "      <td>1.325122e+18</td>\n",
       "      <td>YES! \\nNow we need to win the #USSenate. Or #M...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>1.554225e+09</td>\n",
       "      <td>Ariel baker</td>\n",
       "      <td>archimed115</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-11-08 11:32:27.767174</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>370378</td>\n",
       "      <td>2020-11-04 04:21:54</td>\n",
       "      <td>1.323843e+18</td>\n",
       "      <td>https://t.co/FMw4Wcp14W\\n\\n#Trump #Biden #USAE...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>2.338995e+08</td>\n",
       "      <td>DailyThanthi</td>\n",
       "      <td>dinathanthi</td>\n",
       "      <td>...</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>13.083694</td>\n",
       "      <td>80.270186</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>India</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>TN</td>\n",
       "      <td>2020-11-05 13:01:05.579247</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>769109</td>\n",
       "      <td>2020-11-08 17:10:07</td>\n",
       "      <td>1.325486e+18</td>\n",
       "      <td>#Biden #A vida de Biden pode ser contada de su...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>3.798706e+09</td>\n",
       "      <td>regina bittencourt/ 雷吉娜 · 比滕科特,</td>\n",
       "      <td>regbit1</td>\n",
       "      <td>...</td>\n",
       "      <td>Brasília, Distrito Federal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-11-09 18:34:13.484931</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77684</th>\n",
       "      <td>389103</td>\n",
       "      <td>2020-11-04 08:12:26</td>\n",
       "      <td>1.323901e+18</td>\n",
       "      <td>Kardeşim yıllarca bize #amerikasecimleri forma...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>5.215560e+08</td>\n",
       "      <td>Önder Korkmaz</td>\n",
       "      <td>pirimkorkmaz</td>\n",
       "      <td>...</td>\n",
       "      <td>istanbul</td>\n",
       "      <td>41.009633</td>\n",
       "      <td>28.965165</td>\n",
       "      <td>Istanbul</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Istanbul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-11-05 12:58:22.396263</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77685</th>\n",
       "      <td>179248</td>\n",
       "      <td>2020-10-25 21:26:48</td>\n",
       "      <td>1.320477e+18</td>\n",
       "      <td>#Biden https://t.co/GKdPKn70ot</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>2.314864e+09</td>\n",
       "      <td>Jinghong Cai</td>\n",
       "      <td>jhcai613</td>\n",
       "      <td>...</td>\n",
       "      <td>United States</td>\n",
       "      <td>39.783730</td>\n",
       "      <td>-100.445882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-10-27 18:18:20.253408</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77686</th>\n",
       "      <td>453051</td>\n",
       "      <td>2020-11-05 00:18:53</td>\n",
       "      <td>1.324144e+18</td>\n",
       "      <td>I see the people of Flint came to their senses...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1.208641e+18</td>\n",
       "      <td>Soniabbby</td>\n",
       "      <td>soniabbby</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-11-06 10:11:08.237960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77687</th>\n",
       "      <td>79321</td>\n",
       "      <td>2020-10-21 02:48:38</td>\n",
       "      <td>1.318746e+18</td>\n",
       "      <td>Say it ain't so !\\n\\n#JoeBiden \\n\\n#JoeBuck \\n...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>1.165100e+18</td>\n",
       "      <td>Sam Speed</td>\n",
       "      <td>SamSpee39077935</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-10-27 18:13:37.361841</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77688</th>\n",
       "      <td>593777</td>\n",
       "      <td>2020-11-07 16:49:11</td>\n",
       "      <td>1.325118e+18</td>\n",
       "      <td>#JoeBiden 🍃🌷🍃🌷🍃🌷🌝 https://t.co/1BIzV9meZv</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1.267769e+18</td>\n",
       "      <td>Baran🍁🙏🦜🙏🦜🙏</td>\n",
       "      <td>Barancancigeri1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-11-08 11:19:56.345515</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77689 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0           created_at      tweet_id  \\\n",
       "0          445280  2020-11-04 22:12:10  1.324112e+18   \n",
       "1           38488  2020-10-17 13:32:59  1.317459e+18   \n",
       "2          607448  2020-11-07 17:06:21  1.325122e+18   \n",
       "3          370378  2020-11-04 04:21:54  1.323843e+18   \n",
       "4          769109  2020-11-08 17:10:07  1.325486e+18   \n",
       "...           ...                  ...           ...   \n",
       "77684      389103  2020-11-04 08:12:26  1.323901e+18   \n",
       "77685      179248  2020-10-25 21:26:48  1.320477e+18   \n",
       "77686      453051  2020-11-05 00:18:53  1.324144e+18   \n",
       "77687       79321  2020-10-21 02:48:38  1.318746e+18   \n",
       "77688      593777  2020-11-07 16:49:11  1.325118e+18   \n",
       "\n",
       "                                                   tweet  likes  \\\n",
       "0          Va #Biden adelante... https://t.co/RLELfTU8NW    1.0   \n",
       "1      Did the #democrats not try to impeach #Trump o...    2.0   \n",
       "2      YES! \\nNow we need to win the #USSenate. Or #M...    0.0   \n",
       "3      https://t.co/FMw4Wcp14W\\n\\n#Trump #Biden #USAE...   10.0   \n",
       "4      #Biden #A vida de Biden pode ser contada de su...    0.0   \n",
       "...                                                  ...    ...   \n",
       "77684  Kardeşim yıllarca bize #amerikasecimleri forma...    0.0   \n",
       "77685                     #Biden https://t.co/GKdPKn70ot    0.0   \n",
       "77686  I see the people of Flint came to their senses...    2.0   \n",
       "77687  Say it ain't so !\\n\\n#JoeBiden \\n\\n#JoeBuck \\n...    0.0   \n",
       "77688          #JoeBiden 🍃🌷🍃🌷🍃🌷🌝 https://t.co/1BIzV9meZv    6.0   \n",
       "\n",
       "       retweet_count               source       user_id  \\\n",
       "0                0.0  Twitter for Android  8.758018e+07   \n",
       "1                2.0      Twitter Web App  4.779699e+07   \n",
       "2                0.0      Twitter Web App  1.554225e+09   \n",
       "3                1.0      Twitter Web App  2.338995e+08   \n",
       "4                0.0      Twitter Web App  3.798706e+09   \n",
       "...              ...                  ...           ...   \n",
       "77684            0.0  Twitter for Android  5.215560e+08   \n",
       "77685            0.0  Twitter for Android  2.314864e+09   \n",
       "77686            0.0   Twitter for iPhone  1.208641e+18   \n",
       "77687            0.0  Twitter for Android  1.165100e+18   \n",
       "77688            0.0   Twitter for iPhone  1.267769e+18   \n",
       "\n",
       "                             user_name user_screen_name  ...  \\\n",
       "0                       Abdiel Augusto       augustoexp  ...   \n",
       "1                           Tom Dooley         tomofsnj  ...   \n",
       "2                          Ariel baker      archimed115  ...   \n",
       "3                         DailyThanthi      dinathanthi  ...   \n",
       "4      regina bittencourt/ 雷吉娜 · 比滕科特,          regbit1  ...   \n",
       "...                                ...              ...  ...   \n",
       "77684                    Önder Korkmaz     pirimkorkmaz  ...   \n",
       "77685                     Jinghong Cai         jhcai613  ...   \n",
       "77686                        Soniabbby        soniabbby  ...   \n",
       "77687                        Sam Speed  SamSpee39077935  ...   \n",
       "77688                      Baran🍁🙏🦜🙏🦜🙏  Barancancigeri1  ...   \n",
       "\n",
       "                    user_location        lat        long      city  \\\n",
       "0               Arraiján / Panamá        NaN         NaN       NaN   \n",
       "1                             USA  39.783730 -100.445882       NaN   \n",
       "2                             NaN        NaN         NaN       NaN   \n",
       "3                         Chennai  13.083694   80.270186   Chennai   \n",
       "4      Brasília, Distrito Federal        NaN         NaN       NaN   \n",
       "...                           ...        ...         ...       ...   \n",
       "77684                    istanbul  41.009633   28.965165  Istanbul   \n",
       "77685               United States  39.783730 -100.445882       NaN   \n",
       "77686                         NaN        NaN         NaN       NaN   \n",
       "77687                         NaN        NaN         NaN       NaN   \n",
       "77688                         NaN        NaN         NaN       NaN   \n",
       "\n",
       "             country      continent       state state_code  \\\n",
       "0                NaN            NaN         NaN        NaN   \n",
       "1      United States  North America         NaN        NaN   \n",
       "2                NaN            NaN         NaN        NaN   \n",
       "3              India           Asia  Tamil Nadu         TN   \n",
       "4                NaN            NaN         NaN        NaN   \n",
       "...              ...            ...         ...        ...   \n",
       "77684         Turkey         Europe    Istanbul        NaN   \n",
       "77685  United States  North America         NaN        NaN   \n",
       "77686            NaN            NaN         NaN        NaN   \n",
       "77687            NaN            NaN         NaN        NaN   \n",
       "77688            NaN            NaN         NaN        NaN   \n",
       "\n",
       "                        collected_at  C  \n",
       "0         2020-11-05 12:49:02.541625  0  \n",
       "1      2020-10-21 05:39:00.255677220  0  \n",
       "2         2020-11-08 11:32:27.767174  0  \n",
       "3         2020-11-05 13:01:05.579247  0  \n",
       "4         2020-11-09 18:34:13.484931  0  \n",
       "...                              ... ..  \n",
       "77684     2020-11-05 12:58:22.396263  0  \n",
       "77685     2020-10-27 18:18:20.253408  0  \n",
       "77686     2020-11-06 10:11:08.237960  0  \n",
       "77687     2020-10-27 18:13:37.361841  0  \n",
       "77688     2020-11-08 11:19:56.345515  0  \n",
       "\n",
       "[77689 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56f3832",
   "metadata": {},
   "source": [
    "### cargar dataset elections final 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "659eeb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"preliminares/final_db.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15ae6f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierte los tweets a minúsculas\n",
    "df['tweet'] = df['tweet'].str.lower()\n",
    "\n",
    "# Elimina menciones (@usuario), hashtags (#palabra), URLs y caracteres especiales\n",
    "df['tweet'] = df['tweet'].str.replace(r'@\\w+', '', regex=True)\n",
    "df['tweet'] = df['tweet'].str.replace(r'#\\w+', '', regex=True)\n",
    "df['tweet'] = df['tweet'].str.replace(r'http\\S+', '', regex=True)\n",
    "df['tweet'] = df['tweet'].str.replace(r'\\W+', ' ', regex=True)\n",
    "\n",
    "# Limpieza general\n",
    "df['tweet'] = df['tweet'].str.replace(r'[0-9]', '', regex=True)  # Eliminar números\n",
    "df['tweet'] = df['tweet'].str.replace(r'[^a-záéíóúñ]+', ' ', regex=True)  # Conservar letras y acentos\n",
    "df['tweet'] = df['tweet'].str.replace(r' +', ' ', regex=True).str.strip()  # Eliminar espacios extras\n",
    "\n",
    "# Limpieza específica de nombres propios y palabras clave\n",
    "keywords = ['biden', 'joe', 'donald', 'kamala', 'trump', 'president', 'potus']\n",
    "for keyword in keywords:\n",
    "    df['tweet'] = df['tweet'].str.replace(rf'{keyword}[a-z]*', '', regex=True)\n",
    "\n",
    "# Eliminar palabras muy cortas (de 1 o 2 letras)\n",
    "df['tweet'] = df['tweet'].str.replace(r'\\b\\w{1,2}\\b', '', regex=True)\n",
    "\n",
    "# Limpieza específica de palabras no deseadas\n",
    "esp = [\"want\", \"cnn\", \"https\", \"harris\", \"will\", \"just\", \"vote vote\", \"vote early\", \"rally\", \n",
    "       \"msnbc\", \"did\", \"let\", \"said\", \"doesn\", \"don\", \"know\", \"plan\", \"que\", \"los\", \n",
    "       \"really\", \"way\", \"are\", \"day\", \"united\", \"states\", \"real\", \"eric\", \"man\", \"bye\"]\n",
    "\n",
    "for palabra in esp:\n",
    "    df['tweet'] = df['tweet'].str.replace(rf'\\b{palabra}\\b', '', regex=True)\n",
    "\n",
    "# Eliminar espacios adicionales resultantes de las sustituciones\n",
    "df['tweet'] = df['tweet'].str.replace(r' +', ' ', regex=True).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "40dac2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_30932\\1973815024.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tweet'] = df['tweet'].str.lower()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_30932\\1973815024.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tweet'] = df['tweet'].str.replace(r'@\\w+', '', regex=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_30932\\1973815024.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tweet'] = df['tweet'].str.replace(r'#\\w+', '', regex=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_30932\\1973815024.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tweet'] = df['tweet'].str.replace(r'http\\S+', '', regex=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_30932\\1973815024.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tweet'] = df['tweet'].str.replace(r'\\W+', ' ', regex=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_30932\\1973815024.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tweet'] = df['tweet'].str.replace(r'[0-9]', '', regex=True)  # Eliminar números\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_30932\\1973815024.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tweet'] = df['tweet'].str.replace(r'[^a-záéíóúñ]+', ' ', regex=True)  # Conservar letras y acentos\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_30932\\1973815024.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tweet'] = df['tweet'].str.replace(r' +', ' ', regex=True).str.strip()  # Eliminar espacios extras\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_30932\\1973815024.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tweet'] = df['tweet'].str.replace(rf'{keyword}[a-z]*', '', regex=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_30932\\1973815024.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tweet'] = df['tweet'].str.replace(r'\\b\\w{1,2}\\b', '', regex=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_30932\\1973815024.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tweet'] = df['tweet'].str.replace(rf'\\b{palabra}\\b', '', regex=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_30932\\1973815024.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tweet'] = df['tweet'].str.replace(r' +', ' ', regex=True).str.strip()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "# Convierte los tweets a minúsculas\n",
    "df['tweet'] = df['tweet'].str.lower()\n",
    "\n",
    "# Elimina menciones (@usuario), hashtags (#palabra), URLs y caracteres especiales\n",
    "df['tweet'] = df['tweet'].str.replace(r'@\\w+', '', regex=True)\n",
    "df['tweet'] = df['tweet'].str.replace(r'#\\w+', '', regex=True)\n",
    "df['tweet'] = df['tweet'].str.replace(r'http\\S+', '', regex=True)\n",
    "df['tweet'] = df['tweet'].str.replace(r'\\W+', ' ', regex=True)\n",
    "\n",
    "# Limpieza general\n",
    "df['tweet'] = df['tweet'].str.replace(r'[0-9]', '', regex=True)  # Eliminar números\n",
    "df['tweet'] = df['tweet'].str.replace(r'[^a-záéíóúñ]+', ' ', regex=True)  # Conservar letras y acentos\n",
    "df['tweet'] = df['tweet'].str.replace(r' +', ' ', regex=True).str.strip()  # Eliminar espacios extras\n",
    "\n",
    "# Limpieza específica de nombres propios y palabras clave\n",
    "keywords = ['biden', 'joe', 'donald', 'kamala', 'trump', 'president', 'potus']\n",
    "for keyword in keywords:\n",
    "    df['tweet'] = df['tweet'].str.replace(rf'{keyword}[a-z]*', '', regex=True)\n",
    "\n",
    "# Eliminar palabras muy cortas (de 1 o 2 letras)\n",
    "df['tweet'] = df['tweet'].str.replace(r'\\b\\w{1,2}\\b', '', regex=True)\n",
    "\n",
    "# Limpieza específica de palabras no deseadas\n",
    "esp = [\"want\", \"cnn\", \"https\", \"harris\", \"will\", \"just\", \"vote vote\", \"vote early\", \"rally\", \n",
    "       \"msnbc\", \"did\", \"let\", \"said\", \"doesn\", \"don\", \"know\", \"plan\", \"que\", \"los\", \n",
    "       \"really\", \"way\", \"are\", \"day\", \"united\", \"states\", \"real\", \"eric\", \"man\", \"bye\"]\n",
    "\n",
    "for palabra in esp:\n",
    "    df['tweet'] = df['tweet'].str.replace(rf'\\b{palabra}\\b', '', regex=True)\n",
    "\n",
    "# Eliminar espacios adicionales resultantes de las sustituciones\n",
    "df['tweet'] = df['tweet'].str.replace(r' +', ' ', regex=True).str.strip()\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "489b4e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a84c292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:110: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 217, in _count_physical_cores\n",
      "    raise ValueError(\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>created_at</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>source</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>...</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>continent</th>\n",
       "      <th>state</th>\n",
       "      <th>state_code</th>\n",
       "      <th>collected_at</th>\n",
       "      <th>C</th>\n",
       "      <th>label_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>739852</td>\n",
       "      <td>2020-11-08 01:07:09</td>\n",
       "      <td>1.325243e+18</td>\n",
       "      <td>lets first wait until all the lawsuits finaliz...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>2.540326e+09</td>\n",
       "      <td>SupportIsrael</td>\n",
       "      <td>...</td>\n",
       "      <td>42.360253</td>\n",
       "      <td>-71.058291</td>\n",
       "      <td>Boston</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>North America</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>MA</td>\n",
       "      <td>2020-11-09 18:39:37.699577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>317561</td>\n",
       "      <td>2020-11-03 05:16:46</td>\n",
       "      <td>1.323494e+18</td>\n",
       "      <td>this would make sleep lot better john and pray...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>8.742585e+08</td>\n",
       "      <td>Jonathan Greenberg</td>\n",
       "      <td>...</td>\n",
       "      <td>40.712728</td>\n",
       "      <td>-74.006015</td>\n",
       "      <td>New York</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>North America</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>2020-11-04 09:47:28.623150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>739853</td>\n",
       "      <td>2020-11-08 01:07:09</td>\n",
       "      <td>1.325243e+18</td>\n",
       "      <td>course this desperate certain that the magical...</td>\n",
       "      <td>158.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>1.016349e+18</td>\n",
       "      <td>Corren Love ☆BLACKLIVESMATTER☆</td>\n",
       "      <td>...</td>\n",
       "      <td>39.783730</td>\n",
       "      <td>-100.445882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-11-09 18:39:37.515584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>231729</td>\n",
       "      <td>2020-10-29 15:02:23</td>\n",
       "      <td>1.321830e+18</td>\n",
       "      <td>can wait have and first lady with dignity again</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>1.210572e+09</td>\n",
       "      <td>Juanito 🇲🇽🇺🇸</td>\n",
       "      <td>...</td>\n",
       "      <td>33.749099</td>\n",
       "      <td>-84.390185</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>North America</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>GA</td>\n",
       "      <td>2020-10-30 15:00:34.607781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23</td>\n",
       "      <td>210424</td>\n",
       "      <td>2020-10-28 01:53:04</td>\n",
       "      <td>1.321269e+18</td>\n",
       "      <td>nothing come the scandal first the spin right ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>7.105800e+17</td>\n",
       "      <td>Michael Filippello</td>\n",
       "      <td>...</td>\n",
       "      <td>40.697602</td>\n",
       "      <td>-74.263202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>North America</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>NJ</td>\n",
       "      <td>2020-10-29 16:09:25.008205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26</td>\n",
       "      <td>524483</td>\n",
       "      <td>2020-11-06 13:53:45</td>\n",
       "      <td>1.324712e+18</td>\n",
       "      <td>very popular the cat community and apparently ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>3.041529e+08</td>\n",
       "      <td>Rebel_Maga</td>\n",
       "      <td>...</td>\n",
       "      <td>40.737599</td>\n",
       "      <td>-73.254814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>North America</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "      <td>2020-11-07 11:41:38.371629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31</td>\n",
       "      <td>254337</td>\n",
       "      <td>2020-10-31 01:56:24</td>\n",
       "      <td>1.322357e+18</td>\n",
       "      <td>germany gdp declined you destroyed our economy...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for iPad</td>\n",
       "      <td>4.489442e+07</td>\n",
       "      <td>rick 🇱🇷🇱🇷🇱🇷</td>\n",
       "      <td>...</td>\n",
       "      <td>39.783730</td>\n",
       "      <td>-100.445882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-11-01 11:01:54.606770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52</td>\n",
       "      <td>143150</td>\n",
       "      <td>2020-10-23 13:26:15</td>\n",
       "      <td>1.319631e+18</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>2.488270e+08</td>\n",
       "      <td>Rebekah Johnson 🇺🇸</td>\n",
       "      <td>...</td>\n",
       "      <td>39.739236</td>\n",
       "      <td>-104.984862</td>\n",
       "      <td>Denver</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>North America</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>CO</td>\n",
       "      <td>2020-10-27 18:23:06.420986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>55</td>\n",
       "      <td>332120</td>\n",
       "      <td>2020-11-03 15:16:19</td>\n",
       "      <td>1.323645e+18</td>\n",
       "      <td>make sure all the doors cause these supporters...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>3.107961e+09</td>\n",
       "      <td>🌸🌺🌸</td>\n",
       "      <td>...</td>\n",
       "      <td>39.100105</td>\n",
       "      <td>-94.578142</td>\n",
       "      <td>Kansas City</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>North America</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>MO</td>\n",
       "      <td>2020-11-04 09:45:28.999744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0           created_at      tweet_id  \\\n",
       "1            10      739852  2020-11-08 01:07:09  1.325243e+18   \n",
       "2            11      317561  2020-11-03 05:16:46  1.323494e+18   \n",
       "3            12      739853  2020-11-08 01:07:09  1.325243e+18   \n",
       "4            19      231729  2020-10-29 15:02:23  1.321830e+18   \n",
       "5            23      210424  2020-10-28 01:53:04  1.321269e+18   \n",
       "6            26      524483  2020-11-06 13:53:45  1.324712e+18   \n",
       "7            31      254337  2020-10-31 01:56:24  1.322357e+18   \n",
       "8            52      143150  2020-10-23 13:26:15  1.319631e+18   \n",
       "9            55      332120  2020-11-03 15:16:19  1.323645e+18   \n",
       "\n",
       "                                               tweet  likes  retweet_count  \\\n",
       "1  lets first wait until all the lawsuits finaliz...    0.0            0.0   \n",
       "2  this would make sleep lot better john and pray...    1.0            0.0   \n",
       "3  course this desperate certain that the magical...  158.0           76.0   \n",
       "4    can wait have and first lady with dignity again    0.0            0.0   \n",
       "5  nothing come the scandal first the spin right ...    0.0            0.0   \n",
       "6  very popular the cat community and apparently ...    0.0            0.0   \n",
       "7  germany gdp declined you destroyed our economy...    0.0            0.0   \n",
       "8                                                       0.0            0.0   \n",
       "9  make sure all the doors cause these supporters...    0.0            0.0   \n",
       "\n",
       "                source       user_id                       user_name  ...  \\\n",
       "1   Twitter for iPhone  2.540326e+09                   SupportIsrael  ...   \n",
       "2      Twitter Web App  8.742585e+08              Jonathan Greenberg  ...   \n",
       "3  Twitter for Android  1.016349e+18  Corren Love ☆BLACKLIVESMATTER☆  ...   \n",
       "4   Twitter for iPhone  1.210572e+09                    Juanito 🇲🇽🇺🇸  ...   \n",
       "5   Twitter for iPhone  7.105800e+17              Michael Filippello  ...   \n",
       "6   Twitter for iPhone  3.041529e+08                      Rebel_Maga  ...   \n",
       "7     Twitter for iPad  4.489442e+07                     rick 🇱🇷🇱🇷🇱🇷  ...   \n",
       "8   Twitter for iPhone  2.488270e+08              Rebekah Johnson 🇺🇸  ...   \n",
       "9   Twitter for iPhone  3.107961e+09                             🌸🌺🌸  ...   \n",
       "\n",
       "         lat        long         city                   country  \\\n",
       "1  42.360253  -71.058291       Boston  United States of America   \n",
       "2  40.712728  -74.006015     New York  United States of America   \n",
       "3  39.783730 -100.445882          NaN             United States   \n",
       "4  33.749099  -84.390185      Atlanta  United States of America   \n",
       "5  40.697602  -74.263202          NaN  United States of America   \n",
       "6  40.737599  -73.254814          NaN  United States of America   \n",
       "7  39.783730 -100.445882          NaN             United States   \n",
       "8  39.739236 -104.984862       Denver  United States of America   \n",
       "9  39.100105  -94.578142  Kansas City  United States of America   \n",
       "\n",
       "       continent          state  state_code                collected_at    C  \\\n",
       "1  North America  Massachusetts          MA  2020-11-09 18:39:37.699577  0.0   \n",
       "2  North America       New York          NY  2020-11-04 09:47:28.623150  0.0   \n",
       "3  North America            NaN         NaN  2020-11-09 18:39:37.515584  0.0   \n",
       "4  North America        Georgia          GA  2020-10-30 15:00:34.607781  0.0   \n",
       "5  North America     New Jersey          NJ  2020-10-29 16:09:25.008205  0.0   \n",
       "6  North America       New York          NY  2020-11-07 11:41:38.371629  0.0   \n",
       "7  North America            NaN         NaN  2020-11-01 11:01:54.606770  0.0   \n",
       "8  North America       Colorado          CO  2020-10-27 18:23:06.420986  0.0   \n",
       "9  North America       Missouri          MO  2020-11-04 09:45:28.999744  0.0   \n",
       "\n",
       "  label_cluster  \n",
       "1             2  \n",
       "2             3  \n",
       "3             0  \n",
       "4             2  \n",
       "5             5  \n",
       "6             6  \n",
       "7             4  \n",
       "8             1  \n",
       "9             2  \n",
       "\n",
       "[9 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from transformers import pipeline\n",
    "import tensorflow as tf\n",
    "from transformers import pipeline\n",
    "\n",
    "# Generar embeddings con BERT\n",
    "nlp = pipeline('feature-extraction', model='distilbert-base-uncased')\n",
    "embeddings = [nlp(tweet)[0][0] for tweet in df.tweet]  # Obtener el embedding\n",
    "\n",
    "# Agrupar los tweets usando KMeans\n",
    "n_clusters = 7\n",
    "kmeans = KMeans(n_clusters=n_clusters)\n",
    "kmeans.fit(embeddings)\n",
    "\n",
    "# Asignar etiquetas\n",
    "df['label_cluster'] = kmeans.labels_\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bdef0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n",
      "iteration: 1 of max_iter: 11\n",
      "iteration: 2 of max_iter: 11\n",
      "iteration: 3 of max_iter: 11\n",
      "iteration: 4 of max_iter: 11\n",
      "iteration: 5 of max_iter: 11\n",
      "iteration: 6 of max_iter: 11\n",
      "iteration: 7 of max_iter: 11\n",
      "iteration: 8 of max_iter: 11\n",
      "iteration: 9 of max_iter: 11\n",
      "iteration: 10 of max_iter: 11\n",
      "iteration: 11 of max_iter: 11\n"
     ]
    }
   ],
   "source": [
    "#MATRIZ TERMINO DOCUMENTOS\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pyLDAvis\n",
    "import pyLDAvis.lda_model\n",
    "...\n",
    "pyLDAvis.lda_model.prepare\n",
    "\n",
    "n_vocab = 1500  # tamaño máximo de vocabulario\n",
    "tf_vectorizer = CountVectorizer(max_df=0.8, min_df=2, max_features=n_vocab,\n",
    "                                 stop_words='english', ngram_range=(1, 4))\n",
    "tf = tf_vectorizer.fit_transform(df['tweet'])  # Aplico el objeto a un conjunto de textos\n",
    "\n",
    "# Ajustar el modelo LDA y guardar visualizaciones\n",
    "for i in range(4, 21):\n",
    "    lda = LatentDirichletAllocation(n_components=i, max_iter=11, \n",
    "                                    doc_topic_prior=0.1, topic_word_prior=0.1,\n",
    "                                    n_jobs=-1, random_state=353, verbose=1)  # Construyo el modelo\n",
    "    lda.fit(tf)  # Estimación\n",
    "\n",
    "    # Preparo el modelo para visualización usando pyLDAvis\n",
    "    LDAvis_prepared = pyLDAvis.lda_model.prepare(lda, tf, tf_vectorizer)  \n",
    "    LDAvis_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "169be754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tema 0:\n",
      "['lies', 'declined', 'your', 'with', 'and']\n",
      "Tema 1:\n",
      "['lies', 'declined', 'your', 'with', 'and']\n",
      "Tema 2:\n",
      "['pray', 'able', 'and', 'amp', 'this']\n",
      "Tema 3:\n",
      "['again', 'dignity', 'first', 'with', 'and']\n",
      "Tema 4:\n",
      "['with', 'our', 'nothing', 'right', 'the']\n",
      "Tema 5:\n",
      "['before', 'alzheimer', 'lawsuits', 'wait', 'first']\n",
      "Tema 6:\n",
      "['look', 'they', 'all', 'make', 'about']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Inicializar CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['tweet'])\n",
    "\n",
    "# Inicializar y ajustar LDA\n",
    "lda = LatentDirichletAllocation(n_components=7, random_state=42)\n",
    "lda.fit(X)\n",
    "\n",
    "# Mostrar los temas encontrados\n",
    "for index, topic in enumerate(lda.components_):\n",
    "    print(f'Tema {index}:')\n",
    "    print([vectorizer.get_feature_names_out()[i] for i in topic.argsort()[-5:]])  # Las 5 palabras más relevantes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cb43cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "6a995070",
   "metadata": {},
   "source": [
    "# ideas: 1. usar clasificacion de palabras para tener un numero de topicos generales, \n",
    "2. pero tambien usar embeddings con BERT para tener cluster de senetenciasen vez de clasificar por temas con lda hacerlos por sentencias, usando embeddings\n",
    "3. agrupamos eso y decimos los discursos optimos que deberia dar el politico en esa region\n",
    "4. hay que hacer una ponderacion por likes, por poblacion del estado\n",
    "5. trabajar a nivel estado\n",
    "6. hacer mas limpieza\n",
    "7. hacer como un diagrama con conexiones entre diferentes estados para ver sus preocupaciones, hacer tal vez un mapa de calor para cada cluster, cada cluster en realidad puede tener como un tema central?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
